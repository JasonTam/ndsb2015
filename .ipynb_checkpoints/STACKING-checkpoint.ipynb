{
 "metadata": {
  "name": "",
  "signature": "sha256:893dc6dd98046984b0863ed5502c9d4c3fcba090066dc1e61dbd5c6eccd03c94"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import h5py\n",
      "import pickle\n",
      "from time import time\n",
      "from tools import stack\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.qda import QDA\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "FEAT_TRAIN = '/media/raid_arr/data/ndsb/features/features_train.hdf5'\n",
      "# FEAT_TRAIN = '~/data/ndsb/features/features_train.hdf5'\n",
      "FEAT_TEST = '/media/raid_arr/data/ndsb/features/features_test.hdf5'\n",
      "\n",
      "LAYER = 'fc2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_train = h5py.File(FEAT_TRAIN, 'r')\n",
      "f_test = h5py.File(FEAT_TEST, 'r')\n",
      "train_feats_db = f_train[LAYER]\n",
      "train_lbls_db = f_train['lbls']\n",
      "\n",
      "test_feats_db = f_test[LAYER]\n",
      "test_lbls_db = f_test['lbls']\n",
      "test_paths_db = f_test['im_paths']\n",
      "\n",
      "train_feats = train_feats_db[()]\n",
      "train_lbls = train_lbls_db[()]\n",
      "\n",
      "test_feats = test_feats_db[()]\n",
      "test_lbls = test_lbls_db[()]\n",
      "test_paths = test_paths_db[()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skf = StratifiedKFold(train_lbls_db, n_folds=5, shuffle=True, random_state=0 )\n",
      "\n",
      "clfs = [\n",
      "        svm.SVC(probability=True),\n",
      "        RandomForestClassifier(n_jobs=-1, criterion='entropy'),\n",
      "        ExtraTreesClassifier(n_jobs=-1, criterion='entropy'),\n",
      "        GaussianNB(),\n",
      "        #GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=n_trees)\n",
      "        ]\n",
      "\n",
      "stk = stack.Stacking(LogisticRegression, clfs, skf, stackingc=False, proba=True)\n",
      "\n",
      "tic = time()\n",
      "stk.fit(train_feats, train_lbls)\n",
      "toc = time() - tic\n",
      "print toc\n",
      "\n",
      "pickle.dump(stk, open('/media/raid_arr/data/ndsb/classifiers/STACK_fc2.p', 'wb'))\n",
      "\n",
      "print 'DONE'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training and validating the base (level-0) estimator(s)...\n",
        "\n",
        "Fold [0]\n",
        "  Training base (level-0) estimator 0..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done. 2554.37974119 sec\n",
        "  Training base (level-0) estimator 1... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 28.7118680477 sec\n",
        "  Training base (level-0) estimator 2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 1.69392299652 sec\n",
        "  Training base (level-0) estimator 3... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 0.257086038589 sec\n",
        "Fold [1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Training base (level-0) estimator 0..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done. 2550.16790199 sec\n",
        "  Training base (level-0) estimator 1... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 28.0343458652 sec\n",
        "  Training base (level-0) estimator 2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 1.69406604767 sec\n",
        "  Training base (level-0) estimator 3... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 0.270102977753 sec\n",
        "Fold [2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Training base (level-0) estimator 0..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done. 2574.91269493 sec\n",
        "  Training base (level-0) estimator 1... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 28.4909050465 sec\n",
        "  Training base (level-0) estimator 2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 1.65711593628 sec\n",
        "  Training base (level-0) estimator 3... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 0.256214141846 sec\n",
        "Fold [3]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Training base (level-0) estimator 0..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done. 2566.49723196 sec\n",
        "  Training base (level-0) estimator 1... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 28.1904380322 sec\n",
        "  Training base (level-0) estimator 2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 1.68364691734 sec\n",
        "  Training base (level-0) estimator 3... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 0.245138883591 sec\n",
        "Fold [4]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Training base (level-0) estimator 0..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done. 2568.9092052 sec\n",
        "  Training base (level-0) estimator 1... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 27.3895051479 sec\n",
        "  Training base (level-0) estimator 2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 1.6963570118 sec\n",
        "  Training base (level-0) estimator 3... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done. 0.239163160324 sec\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training meta (level-1) estimator... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done.\n",
        "Re-training base (level-0) estimator 0 on full data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done.\n",
        "Re-training base (level-0) estimator 1 on full data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done.\n",
        "Re-training base (level-0) estimator 2 on full data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done.\n",
        "Re-training base (level-0) estimator 3 on full data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done.\n",
        "17989.346657\n",
        "DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PREDICTION\n",
      "stk = pickle.load(open('/media/raid_arr/data/ndsb/classifiers/STACK_logreg_fc2.p', 'rb'))\n",
      "tic = time()\n",
      "#     pred = clf.predict_proba(test_feats_db)\n",
      "pred = stk.predict_proba(test_feats)\n",
      "print 'Prediction done in:', time() - tic\n",
      "pickle.dump(pred, open('/media/raid_arr/data/ndsb/STACK_fc2_pred.p', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Prediction done in: 6736.06350589\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SUBMISSION CREATION\n",
      "# test_files_all, images, labels = zip(*data)\n",
      "import tools.submission as sub\n",
      "f_name='SUBMISSION_PL_deep_56000_' + clf_name + '_fc2.csv'\n",
      "sub.make_submission(test_paths_db, pred, f_name=f_name)\n",
      "\n",
      "print 'Submission created:', f_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}