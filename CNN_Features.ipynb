{
 "metadata": {
  "name": "",
  "signature": "sha256:7da49dfb1982e3c3e6b56874af033d6fcbc306e72b8b235a8d3a743d34a304fe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import h5py\n",
      "from PIL import Image\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "import lmdb\n",
      "from caffe.proto import caffe_pb2\n",
      "import caffe\n",
      "import matplotlib.pyplot as plt\n",
      "import tools.my_io as my_io\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "# DB_PATH = '/media/raid_arr/data/ndsb/features/pl_56000_feats'\n",
      "# datum = caffe_pb2.Datum()\n",
      "\n",
      "PRETRAINED = '/media/raid_arr/data/ndsb/models/pl_iter_56000.caffemodel'\n",
      "MODEL_FILE = './deploy_deeper.prototxt'\n",
      "MEAN_FILE = '/media/raid_arr/data/ndsb/augment/testaug_mean.npy'\n",
      "LAYER = 'fc2'\n",
      "LAYER2 = 'fc1'\n",
      "OUTPUT = '/media/raid_arr/data/ndsb/features/pl_56000_feats'\n",
      "# N_MBATCH = 1000\n",
      "N = 10000   # Chunk size\n",
      "TEST_IM = '/media/raid_arr/data/ndsb/augment/train/acantharia_protist/100224_rot0.jpg'\n",
      "VALIDATION_DB = './data/64x64/ndsb_test_lmdb'\n",
      "# TRAIN_DB = '/media/raid_arr/data/ndsb/augment/ndsb_trainaug_lmdb/'\n",
      "TRAIN_DB = '/media/raid_arr/data/ndsb/ndsb_train_lmdb'\n",
      "TEST_DB = '/data/ndsb/ndsb_test_lmdb'\n",
      "\n",
      "FEAT_OUT = '/media/raid_arr/data/ndsb/features_test.hdf5'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# image_dims = data[0][1].shape[:2]\n",
      "caffe.set_mode_gpu()\n",
      "# caffe.set_phase_test()\n",
      "image_dims = (64, 64)\n",
      "crop_dims = np.array([57, 57])\n",
      "\n",
      "mean=np.load(MEAN_FILE)\n",
      "mean.shape\n",
      "mean_resized = caffe.io.resize_image(mean.transpose((1,2,0)), crop_dims).transpose((2,0,1))\n",
      "\n",
      "net = caffe.Classifier(MODEL_FILE, PRETRAINED,\n",
      "                       mean=mean_resized,\n",
      "                       raw_scale=1.0,    # 255 if load from caffe.io, 1.0 if load from my_io lmdb\n",
      "                       image_dims=image_dims)\n",
      "\n",
      "n_feats2 = net.blobs['fc2'].data.shape[1]\n",
      "n_feats1 = net.blobs['fc1'].data.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# im = caffe.io.load_image(TEST_IM, color=False)\n",
      "for k, v in net.blobs.items():\n",
      "    print k, v.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data (10, 1, 57, 57)\n",
        "conv1 (10, 96, 14, 14)\n",
        "pool1 (10, 96, 7, 7)\n",
        "conv2 (10, 256, 7, 7)\n",
        "pool2 (10, 256, 3, 3)\n",
        "conv3 (10, 384, 3, 3)\n",
        "conv4 (10, 384, 3, 3)\n",
        "conv5 (10, 256, 3, 3)\n",
        "pool5 (10, 256, 1, 1)\n",
        "fc1 (10, 2048, 1, 1)\n",
        "fc2 (10, 2048, 1, 1)\n",
        "fc3 (10, 121, 1, 1)\n",
        "prob (10, 121, 1, 1)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create new h5 file\n",
      "f.close()\n",
      "f = h5py.File(FEAT_OUT, 'w')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make Groups\n",
      "fc2_db = f.create_dataset(\"fc2\", shape=(N, n_feats2), maxshape=(None, n_feats2), dtype='f')\n",
      "fc1_db = f.create_dataset(\"fc1\", shape=(N, n_feats1), maxshape=(None, n_feats1), dtype='f')\n",
      "lbls_db = f.create_dataset(\"lbls\", shape=(N,), maxshape=(None,), dtype='i8')\n",
      "impaths_db = f.create_dataset(\"im_paths\", shape=(N,), maxshape=(None,), dtype='S120')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PREDICTION TIME\n",
      "print 'Predicting...', TEST_DB\n",
      "prediction_list = []\n",
      "test_files_list = []\n",
      "next_key = ''\n",
      "first_run = True\n",
      "while next_key or first_run:\n",
      "    print 'Starting at key: ', next_key\n",
      "    read_start = time.time()\n",
      "    data_chunk, next_key = my_io.load_lmdb_chunk(TEST_DB, next_key, N)\n",
      "    print \"Read done in %.2f s.\" % (time.time() - read_start)\n",
      "    chunk_len = len(data_chunk)\n",
      "    print 'Chunk size:', chunk_len\n",
      "    sys.stdout.flush()\n",
      "    pred_start = time.time()\n",
      "    \n",
      "    \n",
      "    im_paths = []\n",
      "    feats_fc2 = []\n",
      "    feats_fc1 = []\n",
      "    lbls = []\n",
      "    if not first_run:\n",
      "        fc2_db.resize(fc2_db.shape[0] + chunk_len, axis=0)\n",
      "        fc1_db.resize(fc1_db.shape[0] + chunk_len, axis=0)\n",
      "        lbls_db.resize(lbls_db.shape[0] + chunk_len, axis=0)\n",
      "        impaths_db.resize(impaths_db.shape[0] + chunk_len, axis=0)\n",
      "    for ii, (im_path, im, lbl) in enumerate(data_chunk):\n",
      "    #     print im_path\n",
      "    #     print im.shape\n",
      "    #     print lbl\n",
      "        prediction = net.predict([im])\n",
      "        feat_fc2 = np.squeeze(net.blobs['fc2'].data.mean(0))\n",
      "        feat_fc1 = np.squeeze(net.blobs['fc1'].data.mean(0))\n",
      "        feats_fc2.append(feat_fc2)\n",
      "        feats_fc1.append(feat_fc1)\n",
      "        lbls.append(lbl)\n",
      "        im_paths.append(im_path)\n",
      "    fc2_db[-chunk_len:] = np.array(feats_fc2)\n",
      "    fc1_db[-chunk_len:] = np.array(feats_fc1)\n",
      "    lbls_db[-chunk_len:] = np.array(lbls)\n",
      "    impaths_db[-chunk_len:] = np.array(im_paths)\n",
      "        \n",
      "    \n",
      "#     im_path_chunk, images_chunk, labels_chunk = zip(*data_chunk)\n",
      "#     prediction = net.predict(images_chunk)\n",
      "#     prediction_list.append(prediction)\n",
      "#     test_files_list.append(test_files_chunk)\n",
      "    print \"Pred done in %.2f s.\" % (time.time() - pred_start)\n",
      "    sys.stdout.flush()\n",
      "    first_run = False\n",
      "    \n",
      "# predictions = np.concatenate(prediction_list)\n",
      "# test_files = list(itertools.chain(*test_files_list))\n",
      "print \"Done predicting\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting... /data/ndsb/ndsb_test_lmdb\n",
        "Starting at key:  \n",
        "Read done in 1.47 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.60 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00010000_/data/ndsb/test/131890.jpg\n",
        "Read done in 1.51 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.63 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00020000_/data/ndsb/test/143698.jpg\n",
        "Read done in 1.46 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.60 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00030000_/data/ndsb/test/127171.jpg\n",
        "Read done in 1.43 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.53 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00040000_/data/ndsb/test/9227.jpg\n",
        "Read done in 1.41 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.57 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00050000_/data/ndsb/test/132350.jpg\n",
        "Read done in 1.41 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.58 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00060000_/data/ndsb/test/74795.jpg\n",
        "Read done in 1.38 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.54 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00070000_/data/ndsb/test/135220.jpg\n",
        "Read done in 1.37 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.58 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00080000_/data/ndsb/test/56438.jpg\n",
        "Read done in 1.35 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.58 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00090000_/data/ndsb/test/45426.jpg\n",
        "Read done in 1.33 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.65 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00100000_/data/ndsb/test/64677.jpg\n",
        "Read done in 1.31 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.60 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00110000_/data/ndsb/test/111353.jpg\n",
        "Read done in 1.30 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.55 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00120000_/data/ndsb/test/145818.jpg\n",
        "Read done in 1.28 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 225.57 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting at key:  00130000_/data/ndsb/test/153380.jpg\n",
        "Read done in 0.06 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Chunk size: 400\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pred done in 9.03 s.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done predicting\n"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "prediction = net.predict(images)\n",
      "print \"Done in %.2f s.\" % (time.time() - start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done in 131.15 s.\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feats = []\n",
      "y = []\n",
      "tic = time.time()\n",
      "for ii, (im_path, im, lbl) in enumerate(data):\n",
      "#     print im_path\n",
      "#     print im.shape\n",
      "#     print lbl\n",
      "    prediction = net.predict([im])\n",
      "    fc2 = np.squeeze(net.blobs['fc2'].data.mean(0))\n",
      "    feats.append(fc2)\n",
      "    y.append(lbl)\n",
      "    \n",
      "    if ii%1000==0:\n",
      "        print ii\n",
      "#     break\n",
      "# prediction.shape\n",
      "# fc2.shape\n",
      "print \"Done in %.2f s.\" % (time.time() - tic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done in 136.09 s."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.array(y)\n",
      "feats_arr = np.array(feats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "clf = svm.SVC()\n",
      "\n",
      "scores = cross_validation.cross_val_score(clf, feats_arr, y, cv=5)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:413: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
        "  % (min_labels, self.n_folds)), Warning)\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "[u'fc1', u'fc2', u'im_paths', u'lbls']"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}