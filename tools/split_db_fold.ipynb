{
 "metadata": {
  "name": "",
  "signature": "sha256:ddf3f9ee82430105a11ce0f96cf35f7191c53d3b315c39b5d0c86be1dfa44ff8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import plyvel\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "TRAIN_FULL_PATH = '/media/raid_arr/tmp/normed_lvl'    # DB to split\n",
      "TRAIN_FOLD_PATH = '/media/raid_arr/tmp/train0_norm_lvl'    # Output train\n",
      "TEST_FOLD_PATH = '/media/raid_arr/tmp/test0_norm_lvl'    # Output test\n",
      "\n",
      "TRAIN_FOLD_TXT = '/media/raid_arr/data/ndsb/folds/train0.txt'\n",
      "TEST_FOLD_TXT = '/media/raid_arr/data/ndsb/folds/test0.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab the image paths from the folds that were already generated\n",
      "train_fold_paths = np.loadtxt(TRAIN_FOLD_TXT, delimiter='\\t', dtype=str)[:, 0]\n",
      "test_fold_paths = np.loadtxt(TEST_FOLD_TXT, delimiter='\\t', dtype=str)[:, 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get image name from path and shuffle order\n",
      "train_fold_names = np.array([os.path.basename(p) for p in train_fold_paths])\n",
      "test_fold_names = np.array([os.path.basename(p) for p in test_fold_paths])\n",
      "np.random.shuffle(train_fold_names)\n",
      "np.random.shuffle(test_fold_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open new db's and fill\n",
      "db_train_full = plyvel.DB(TRAIN_FULL_PATH)\n",
      "db_train_fold = plyvel.DB(TRAIN_FOLD_PATH, create_if_missing=True)\n",
      "wb_train_fold = db_train_fold.write_batch()\n",
      "db_test_fold = plyvel.DB(TEST_FOLD_PATH, create_if_missing=True)\n",
      "wb_test_fold = db_test_fold.write_batch()\n",
      "\n",
      "# Insert in shuffled order\n",
      "for im_name in train_fold_names:\n",
      "    db_train_fold.put(str(im_name), db_train_full.get(str(im_name)))\n",
      "for im_name in test_fold_names:\n",
      "    db_test_fold.put(str(im_name), db_train_full.get(str(im_name)))\n",
      "    \n",
      "wb_train_fold.write()\n",
      "wb_test_fold.write()\n",
      "\n",
      "db_train_full.close()\n",
      "db_train_fold.close()\n",
      "db_test_fold.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db_train_full.close()\n",
      "db_train_fold.close()\n",
      "db_test_fold.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import shuffle\n",
      "import my_io\n",
      "reload(my_io)\n",
      "shuffle(train_fold_paths)\n",
      "shuffle(test_fold_paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TRAIN_FOLD_PATH = '/media/raid_arr/tmp/train0_norm_lmdb'    # Output train\n",
      "TEST_FOLD_PATH = '/media/raid_arr/tmp/test0_norm_lmdb'    # Output test\n",
      "\n",
      "my_io.multi_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='lmdb',\n",
      "                    perturb=False, verbose=True)\n",
      "my_io.single_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='lmdb',\n",
      "                    perturb=False, verbose=True)\n",
      "\n",
      "my_io.single_extract(test_fold_paths, TEST_FOLD_PATH, backend='lmdb',\n",
      "                    perturb=False, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 266, in _feed\n",
        "    send(obj)\n",
        "PicklingError: Can't pickle <class 'my_io.ExtractionTask'>: attribute lookup my_io.ExtractionTask failed\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-25-827e774e81e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m my_io.multi_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='lmdb',\n\u001b[1;32m----> 5\u001b[1;33m                     perturb=False, verbose=True)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# my_io.single_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='lmdb',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#                     perturb=False, verbose=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/afs/ee.cooper.edu/user/t/a/tam8/documents/ndsb2015/tools/my_io.pyc\u001b[0m in \u001b[0;36mmulti_extract\u001b[1;34m(im_files, db_path, backend, perturb, out_shape, verbose)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;31m# Wait for all of the tasks to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;31m# Combine Results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/multiprocessing/queues.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unfinished_tasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/multiprocessing/synchronize.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;31m# wait for notification or timeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_semaphore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# indicate that this thread has woken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create aug\n",
      "TRAIN_FOLD_PATH = '/media/raid_arr/tmp/train0_normaug_lvl'    # Output train\n",
      "\n",
      "\n",
      "my_io.multi_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='leveldb',\n",
      "                    perturb=True, verbose=True)\n",
      "\n",
      "\n",
      "my_io.single_extract(train_fold_paths, TRAIN_FOLD_PATH, backend='lmdb',\n",
      "                    perturb=False, verbose=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_io.single_extract(test_fold_paths, TEST_FOLD_PATH, perturb=False, verbose=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exrtaction to db done in 156 s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/site-packages/skimage/util/dtype.py:107: UserWarning: Possible precision loss when converting from float64 to uint8\n",
        "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Moving Extracted Features to another DB with same order"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from caffe.proto import caffe_pb2\n",
      "from time import time\n",
      "import lmdb\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DB = '/media/raid_arr/tmp/train0_norm_lmdb/'\n",
      "# DB_FEATS = '/media/raid_arr/tmp/train0_norm_feats_lmdb'\n",
      "DB = '/media/raid_arr/tmp/test0_norm_lmdb/'\n",
      "DB_FEATS = '/media/raid_arr/tmp/test0_norm_feats_lmdb'\n",
      "\n",
      "# DB = '/media/raid_arr/tmp/train0_norm_lmdb/'\n",
      "# DB_FEATS = '/media/raid_arr/tmp/train0_norm_feats_simp_lmdb'\n",
      "# DB = '/media/raid_arr/tmp/test0_norm_lmdb/'\n",
      "# DB_FEATS = '/media/raid_arr/tmp/test0_norm_feats_simp_lmdb'\n",
      "\n",
      "def make_feats_db(core_db=DB, feats_db=DB_FEATS, verbose=False):\n",
      "    db = lmdb.open(core_db)\n",
      "    db_feats = lmdb.open(feats_db, map_size=1e12)\n",
      "    txn = db.begin()\n",
      "    c = txn.cursor()\n",
      "    txn_feats = db_feats.begin(write=True)\n",
      "\n",
      "    std_scale = 2.\n",
      "    tic = time()\n",
      "    for k, v in c:\n",
      "        datum = caffe_pb2.Datum()\n",
      "        datum.ParseFromString(v)\n",
      "        extra_feats = np.array([\n",
      "            datum.orig_space,\n",
      "            datum.orig_height,\n",
      "            datum.orig_width,\n",
      "            datum.extent,\n",
      "            datum.hu1,\n",
      "            datum.hu2,\n",
      "            datum.hu3,\n",
      "            datum.hu4,\n",
      "            datum.hu5,\n",
      "            datum.hu6,\n",
      "            datum.hu7,\n",
      "            datum.solidity,\n",
      "        ])[None, None, :]\n",
      "        datum.channels, datum.height, datum.width = extra_feats.shape\n",
      "        scale_map = ((extra_feats + std_scale) * 128./std_scale).clip(0, 255).astype('uint8')  # 2 std\n",
      "        datum.data = scale_map.tobytes()\n",
      "    #     datum.float_data.extend(extra_feats.flat)\n",
      "        v_feats = datum.SerializeToString()\n",
      "        txn_feats.put(k, v_feats)\n",
      "\n",
      "    txn_feats.commit()\n",
      "    db.close()\n",
      "    db_feats.close()\n",
      "    \n",
      "    if verbose:\n",
      "        print 'Feat transfer done:', time() - tic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "make_feats_db(verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.65424895287\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import my_io\n",
      "reload(my_io)\n",
      "DB = '/media/raid_arr/tmp/test0_norm_lmdb/'\n",
      "DB_FEATS = '/media/raid_arr/tmp/test0_norm_feats_lmdb'\n",
      "my_io.transfer_feats_db(core_db=DB, \n",
      "                        feats_db=DB_FEATS,\n",
      "                        backend='lmdb',\n",
      "                        verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feat transfer done: 1.69103503227\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "'\\xc1\\xac\\xa4\\x98\\xff\\xdd\\xf1\\xf4\\xfd\\xf9\\xffu'"
       ]
      }
     ],
     "prompt_number": 58
    }
   ],
   "metadata": {}
  }
 ]
}